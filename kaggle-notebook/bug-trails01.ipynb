{"cells":[{"cell_type":"markdown","id":"header","metadata":{},"source":"# 🏆 Victory36 qRIX - ARC Prize 2025 Submission\nTeam: Victory36 Labs / AI Publishing International LLP  \nContact: pr@coaching2100.com  \nLicense: CC BY 4.0  \nCitation: Chollet, François, et al. \"ARC Prize 2025.\" Kaggle, 2025"},{"cell_type":"code","execution_count":null,"id":"imports","metadata":{},"outputs":[],"source":"import json\nimport numpy as np\nimport time\nimport os"},{"cell_type":"code","execution_count":null,"id":"load_data","metadata":{},"outputs":[],"source":"# 🔍 Load ARC dataset - handles both test and evaluation sets\nbase_path = \"/kaggle/input/arc-prize-2025\"\n\nprint(\"Available ARC dataset files:\")\nif os.path.exists(base_path):\n    for f in os.listdir(base_path):\n        print(f\" - {f}\")\n\n# Try test challenges first (for competition), then evaluation\nchallenges = None\ndata_source = None\n\ntry:\n    test_path = f\"{base_path}/arc-agi_test_challenges.json\"\n    if os.path.exists(test_path):\n        with open(test_path, 'r') as f:\n            challenges = json.load(f)\n        data_source = \"test_challenges (COMPETITION MODE)\"\n    else:\n        eval_path = f\"{base_path}/arc-agi_evaluation_challenges.json\"\n        with open(eval_path, 'r') as f:\n            challenges = json.load(f)\n        data_source = \"evaluation_challenges (DEVELOPMENT MODE)\"\nexcept Exception as e:\n    print(f\"Error loading Kaggle data: {e}\")\n    # Fallback for local testing\n    challenges = {\n        \"sample\": {\n            \"train\": [{\"input\": [[0,1],[1,0]], \"output\": [[1,0],[0,1]]}],\n            \"test\": [{\"input\": [[0,0,1],[1,0,0],[0,1,1]]}]\n        }\n    }\n    data_source = \"fallback sample\"\n\nprint(f\"\\n📊 Loaded {len(challenges)} tasks from {data_source}\")"},{"cell_type":"code","execution_count":null,"id":"qrix_solver","metadata":{},"outputs":[],"source":"def qrix_solver(train_pairs, test_input):\n    \"\"\"Victory36 qRIX solver with enhanced pattern recognition\"\"\"\n    try:\n        test_array = np.array(test_input)\n        \n        if not train_pairs or len(train_pairs) == 0:\n            return test_input\n        \n        # Use first training example for pattern detection\n        input_train = np.array(train_pairs[0][\"input\"])\n        output_train = np.array(train_pairs[0][\"output\"])\n        \n        # Strategy 1: Same size transformations\n        if input_train.shape == output_train.shape:\n            # Binary inversion pattern\n            unique_vals = np.unique(np.concatenate([input_train.flatten(), output_train.flatten()]))\n            if len(unique_vals) <= 2 and np.array_equal(input_train, 1 - output_train):\n                result = (1 - test_array)\n                return np.clip(result, 0, 9).tolist()\n            \n            # Border filling pattern\n            if np.sum(output_train) > np.sum(input_train):\n                result = np.copy(test_array)\n                if test_array.shape[0] >= 2 and test_array.shape[1] >= 2:\n                    result[0, :] = 1; result[-1, :] = 1\n                    result[:, 0] = 1; result[:, -1] = 1\n                return result.tolist()\n        \n        # Strategy 2: Size scaling patterns\n        elif output_train.shape != input_train.shape:\n            if input_train.shape[0] > 0 and input_train.shape[1] > 0:\n                scale_h = test_array.shape[0] / input_train.shape[0]\n                scale_w = test_array.shape[1] / input_train.shape[1]\n                result = np.zeros_like(test_array)\n                for i in range(min(output_train.shape[0], result.shape[0])):\n                    for j in range(min(output_train.shape[1], result.shape[1])):\n                        new_i, new_j = int(i * scale_h), int(j * scale_w)\n                        if new_i < result.shape[0] and new_j < result.shape[1]:\n                            result[new_i, new_j] = output_train[i, j]\n                return result.tolist()\n        \n        return test_input\n    except Exception as e:\n        print(f\"qRIX solver error on task: {e}\")\n        return test_input\n\nprint(\"✅ qRIX solver loaded successfully\")"},{"cell_type":"code","execution_count":null,"id":"generate_predictions","metadata":{},"outputs":[],"source":"# 🚀 Generate ALL predictions\nprint(\"🎯 Victory36 qRIX - Generating Predictions\")\nprint(\"=\" * 60)\nprint(f\"🚀 Processing ALL {len(challenges)} tasks...\")\n\nresults = {}\nstart_time = time.time()\n\n# Process ALL tasks (no subset limit for full 400)\nfor i, (task_id, task_data) in enumerate(challenges.items()):\n    if i % 100 == 0 and i > 0:\n        print(f\"   ... processed {i} tasks\")\n    \n    task_results = []\n    for test_case in task_data[\"test\"]:\n        prediction = qrix_solver(task_data[\"train\"], test_case[\"input\"])\n        task_results.append({\n            \"attempt_1\": prediction,\n            \"attempt_2\": prediction  # Deterministic solver\n        })\n    results[task_id] = task_results\n\n# Build complete submission\nsubmission = {\n    \"_metadata\": {\n        \"submission\": \"Victory36 qRIX\",\n        \"team\": \"Victory36 Labs / AI Publishing International LLP\",\n        \"contact\": \"pr@coaching2100.com\",\n        \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S UTC\"),\n        \"tasks_processed\": len(challenges),\n        \"license\": \"CC BY 4.0\",\n        \"citation\": \"Chollet, Francois, et al. 'ARC Prize 2025.' Kaggle, 2025\",\n        \"processing_time\": f\"{time.time() - start_time:.3f}s\"\n    },\n    **results\n}\n\n# Save submission\nwith open('submission.json', 'w') as f:\n    json.dump(submission, f)\n\nprint(f\"✅ Generated {len(challenges)} predictions in {time.time() - start_time:.3f}s\")\nprint(f\"📁 Saved to: submission.json\")"},{"cell_type":"code","execution_count":null,"id":"validation","metadata":{},"outputs":[],"source":"# 🔍 Validation Cell\nprint(\"🔍 VICTORY36 qRIX - Submission Validation\")\nprint(\"=\" * 60)\n\ntry:\n    with open(\"submission.json\", \"r\") as f:\n        submission = json.load(f)\n\n    # Task keys\n    task_keys = [k for k in submission.keys() if not k.startswith(\"_\")]\n    num_tasks = len(task_keys)\n\n    # Task Count\n    print(f\"📊 Task Count: {num_tasks} tasks\")\n    expected = 400 if \"test_challenges\" in data_source else len(challenges)\n    print(\"   Status:\", \"✅ PERFECT\" if num_tasks == expected else f\"⚠️ {num_tasks}/{expected}\")\n\n    # Structure Check (sample 5 tasks)\n    invalid_structs = []\n    for task_id in list(task_keys)[:5]:\n        entries = submission[task_id]\n        if not isinstance(entries, list) or len(entries) == 0:\n            invalid_structs.append(f\"{task_id}: not a list\")\n            continue\n        if not all(isinstance(e, dict) and \"attempt_1\" in e and \"attempt_2\" in e for e in entries):\n            invalid_structs.append(f\"{task_id}: missing attempt keys\")\n\n    print(f\"\\n🏗️ Structure Check: {'✅ PERFECT' if not invalid_structs else '❌ Issues found'}\")\n    if invalid_structs:\n        for err in invalid_structs[:3]:\n            print(\"   -\", err)\n\n    # Metadata Check\n    required_fields = [\"submission\", \"team\", \"contact\", \"timestamp\", \"tasks_processed\", \"license\", \"citation\"]\n    missing_meta = [f for f in required_fields if f not in submission[\"_metadata\"]]\n\n    print(f\"\\n📋 Metadata Check: {'✅ COMPLETE' if not missing_meta else '❌ Missing'}\")\n    if missing_meta:\n        print(\"   Missing fields:\", missing_meta)\n\n    # Final Status\n    all_good = not invalid_structs and num_tasks == expected and not missing_meta\n    print(f\"\\n📈 FINAL STATUS: {'🎉 SUBMISSION READY' if all_good else '⚠️ NEEDS REVIEW'}\")\n    \n    if all_good:\n        print(f\"\\n🏆 Victory36 qRIX submission validated: {num_tasks} tasks processed successfully!\")\n    \nexcept Exception as e:\n    print(f\"❌ Validation failed: {e}\")"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91496,"databundleVersionId":11802066,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat":4,"nbformat_minor":5}