#!/usr/bin/env python3
"""
Integration Reference Updater
=============================

This script updates integration references in code files after JSON structures 
have been flattened, using the mapping reports generated by the flattening tool.

Features:
- Updates JavaScript/TypeScript/Python code references
- Processes multiple mapping reports at once
- Creates backup files before making changes
- Generates a report of all changes made

Usage:
    python update-integration-refs.py --mapping-report <report.json> --code-dir <path>
    python update-integration-refs.py --mapping-reports-dir <path> --code-dir <path> --recursive
"""

import json
import argparse
import os
import re
import sys
from pathlib import Path
from typing import Dict, List, Set, Tuple
from datetime import datetime

class IntegrationReferenceUpdater:
    def __init__(self, dry_run: bool = False):
        """
        Initialize the reference updater.
        
        Args:
            dry_run: If True, only report what would be changed without making changes
        """
        self.dry_run = dry_run
        self.mappings = {}  # Combined mappings from all reports
        self.changes_made = []  # Track all changes for reporting
        
        # File extensions to process
        self.supported_extensions = {'.js', '.ts', '.jsx', '.tsx', '.py', '.json', '.md'}
        
        # Patterns for different reference types in code
        self.reference_patterns = [
            # JSON property access: obj.members.user1.name -> obj["members__user1__name"]
            (r'\.([a-zA-Z_][a-zA-Z0-9_]*(?:\.[a-zA-Z_][a-zA-Z0-9_]*)+)', 'dot_notation'),
            # String literals: "members.user1.name" -> "members__user1__name"
            (r'"([a-zA-Z_][a-zA-Z0-9_]*(?:\.[a-zA-Z_][a-zA-Z0-9_]*)+)"', 'string_literal'),
            # Single quotes: 'members.user1.name' -> 'members__user1__name'
            (r"'([a-zA-Z_][a-zA-Z0-9_]*(?:\.[a-zA-Z_][a-zA-Z0-9_]*)+)'", 'single_quote_string'),
            # Template literals: `${obj.members.user1.name}` -> `${obj["members__user1__name"]}`
            (r'`([^`]*\$\{[^}]*\.([a-zA-Z_][a-zA-Z0-9_]*(?:\.[a-zA-Z_][a-zA-Z0-9_]*)+)[^}]*\}[^`]*)`', 'template_literal'),
        ]
    
    def load_mapping_reports(self, report_paths: List[str]):
        """Load and combine mapping reports from multiple files."""
        for report_path in report_paths:
            try:
                with open(report_path, 'r', encoding='utf-8') as f:
                    report = json.load(f)
                
                if 'key_mappings' in report:
                    # Single file report
                    self.mappings.update(report['key_mappings'])
                elif 'file_mappings' in report:
                    # Combined directory report
                    for file_mappings in report['file_mappings'].values():
                        self.mappings.update(file_mappings)
                
                print(f"Loaded mappings from: {report_path}")
                
            except Exception as e:
                print(f"Error loading {report_path}: {e}")
    
    def should_update_reference(self, original_path: str) -> bool:
        """Check if a reference should be updated based on our mappings."""
        return original_path in self.mappings and self.mappings[original_path] != original_path
    
    def update_dot_notation(self, content: str) -> Tuple[str, List[str]]:
        """Update dot notation property access to bracket notation."""
        changes = []
        
        def replace_dot_notation(match):
            full_path = match.group(1)
            if self.should_update_reference(full_path):
                flattened_key = self.mappings[full_path]
                changes.append(f"Dot notation: .{full_path} -> [\"{flattened_key}\"]")
                return f'["{flattened_key}"]'
            return match.group(0)
        
        pattern = r'\.([a-zA-Z_][a-zA-Z0-9_]*(?:\.[a-zA-Z_][a-zA-Z0-9_]*)+)(?=\s*[^a-zA-Z0-9_.])'
        updated_content = re.sub(pattern, replace_dot_notation, content)
        
        return updated_content, changes
    
    def update_string_literals(self, content: str) -> Tuple[str, List[str]]:
        """Update string literal references."""
        changes = []
        
        def replace_string_literal(match):
            quote_char = match.group(0)[0]  # " or '
            path = match.group(1)
            if self.should_update_reference(path):
                flattened_key = self.mappings[path]
                changes.append(f"String literal: {quote_char}{path}{quote_char} -> {quote_char}{flattened_key}{quote_char}")
                return f'{quote_char}{flattened_key}{quote_char}'
            return match.group(0)
        
        # Handle both double and single quotes
        patterns = [
            r'"([a-zA-Z_][a-zA-Z0-9_]*(?:\.[a-zA-Z_][a-zA-Z0-9_]*)+)"',
            r"'([a-zA-Z_][a-zA-Z0-9_]*(?:\.[a-zA-Z_][a-zA-Z0-9_]*)+)'"
        ]
        
        updated_content = content
        for pattern in patterns:
            updated_content = re.sub(pattern, replace_string_literal, updated_content)
        
        return updated_content, changes
    
    def update_file_content(self, file_path: str) -> List[str]:
        """Update a single file's content and return list of changes made."""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                original_content = f.read()
            
            updated_content = original_content
            all_changes = []
            
            # Apply different types of updates
            updated_content, dot_changes = self.update_dot_notation(updated_content)
            all_changes.extend(dot_changes)
            
            updated_content, string_changes = self.update_string_literals(updated_content)
            all_changes.extend(string_changes)
            
            # If changes were made and not in dry-run mode, write the file
            if all_changes and updated_content != original_content:
                if not self.dry_run:
                    # Create backup
                    backup_path = f"{file_path}.backup"
                    with open(backup_path, 'w', encoding='utf-8') as f:
                        f.write(original_content)
                    
                    # Write updated content
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(updated_content)
                    
                    print(f"Updated: {file_path} (backup: {backup_path})")
                else:
                    print(f"Would update: {file_path}")
                
                # Track changes for reporting
                for change in all_changes:
                    self.changes_made.append({
                        'file': file_path,
                        'change': change,
                        'timestamp': datetime.now().isoformat()
                    })
            
            return all_changes
            
        except Exception as e:
            print(f"Error processing {file_path}: {e}")
            return []
    
    def process_directory(self, directory_path: str, recursive: bool = False) -> Dict[str, List[str]]:
        """Process all supported files in a directory."""
        directory = Path(directory_path)
        
        if not directory.exists():
            raise FileNotFoundError(f"Directory not found: {directory_path}")
        
        # Find files to process
        if recursive:
            files_to_process = []
            for ext in self.supported_extensions:
                files_to_process.extend(directory.rglob(f"*{ext}"))
        else:
            files_to_process = []
            for ext in self.supported_extensions:
                files_to_process.extend(directory.glob(f"*{ext}"))
        
        results = {}
        
        for file_path in files_to_process:
            # Skip backup files and flattened files
            if file_path.name.endswith('.backup') or '_flattened' in file_path.name:
                continue
                
            changes = self.update_file_content(str(file_path))
            if changes:
                results[str(file_path)] = changes
        
        return results
    
    def generate_update_report(self, output_path: str):
        """Generate a report of all changes made."""
        report = {
            "timestamp": datetime.now().isoformat(),
            "dry_run": self.dry_run,
            "total_mappings_loaded": len(self.mappings),
            "files_changed": len(set(change['file'] for change in self.changes_made)),
            "total_changes": len(self.changes_made),
            "changes_by_file": {},
            "all_changes": self.changes_made,
            "sample_mappings": dict(list(self.mappings.items())[:10])  # First 10 mappings for reference
        }
        
        # Group changes by file
        for change in self.changes_made:
            file_path = change['file']
            if file_path not in report["changes_by_file"]:
                report["changes_by_file"][file_path] = []
            report["changes_by_file"][file_path].append(change['change'])
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"Update report saved: {output_path}")

def main():
    parser = argparse.ArgumentParser(description="Update integration references after JSON flattening")
    parser.add_argument("--mapping-report", "-m", help="Path to a single mapping report JSON file")
    parser.add_argument("--mapping-reports-dir", "-d", help="Directory containing mapping report files")
    parser.add_argument("--code-dir", "-c", required=True, help="Directory containing code files to update")
    parser.add_argument("--recursive", "-r", action="store_true", help="Process directories recursively")
    parser.add_argument("--dry-run", action="store_true", help="Show what would be changed without making changes")
    parser.add_argument("--report-output", "-o", help="Path to save the update report")
    
    args = parser.parse_args()
    
    if not args.mapping_report and not args.mapping_reports_dir:
        parser.error("Either --mapping-report or --mapping-reports-dir must be specified")
    
    # Initialize updater
    updater = IntegrationReferenceUpdater(dry_run=args.dry_run)
    
    try:
        # Load mapping reports
        report_paths = []
        
        if args.mapping_report:
            report_paths.append(args.mapping_report)
        
        if args.mapping_reports_dir:
            reports_dir = Path(args.mapping_reports_dir)
            if reports_dir.exists():
                report_paths.extend(str(p) for p in reports_dir.rglob("*mapping_report.json"))
                report_paths.extend(str(p) for p in reports_dir.rglob("flattening_report.json"))
        
        if not report_paths:
            print("No mapping report files found")
            return
        
        updater.load_mapping_reports(report_paths)
        
        if not updater.mappings:
            print("No mappings loaded from report files")
            return
        
        print(f"Loaded {len(updater.mappings)} key mappings")
        
        # Process code files
        if args.dry_run:
            print("DRY RUN MODE - No files will be modified")
        
        results = updater.process_directory(args.code_dir, recursive=args.recursive)
        
        # Generate report
        report_output = args.report_output or f"update_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        updater.generate_update_report(report_output)
        
        # Summary
        files_with_changes = len(results)
        total_changes = sum(len(changes) for changes in results.values())
        
        print(f"\nSummary:")
        print(f"- Files with changes: {files_with_changes}")
        print(f"- Total changes: {total_changes}")
        
        if args.dry_run:
            print("- Run without --dry-run to apply changes")
    
    except Exception as e:
        print(f"Error: {e}", file=sys.stderr)
        sys.exit(1)

if __name__ == "__main__":
    main()